{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b37dcae2",
   "metadata": {},
   "source": [
    "self attention mechanism is also called *scaled dot-product attention*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4848ac",
   "metadata": {},
   "source": [
    "*computing attention weights step by step*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa351ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "inputs = torch.tensor([\n",
    "    [0.43, 0.15, 0.89],  # your        (x^1)\n",
    "    [0.55, 0.87, 0.66],  # journey     (x^2)\n",
    "    [0.57, 0.85, 0.64],  # starts     (x^3)\n",
    "    [0.22, 0.58, 0.33],  # with       (x^4)\n",
    "    [0.77, 0.25, 0.10],  # one        (x^5)\n",
    "    [0.05, 0.80, 0.55]  # step        (X^6)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0656f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4300, 0.1500, 0.8900],\n",
      "        [0.5500, 0.8700, 0.6600],\n",
      "        [0.5700, 0.8500, 0.6400],\n",
      "        [0.2200, 0.5800, 0.3300],\n",
      "        [0.7700, 0.2500, 0.1000],\n",
      "        [0.0500, 0.8000, 0.5500]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a68333aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a561a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]  # [0.5500, 0.8700, 0.6600]\n",
    "d_in=inputs.shape[1] # input embedding size (3)\n",
    "d_out=2  # output embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a26e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing 3 weights matrices (weight parameters)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "W_query=torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key=torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value=torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "\n",
    "# required_grad = True duing model training must\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72dd6743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])\n"
     ]
    }
   ],
   "source": [
    "print(W_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a2d53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2=x_2@W_query # query vector for token 2\n",
    "key_2=x_2@W_key # key vector for token 2\n",
    "value_2=x_2@W_value # valuevector for token 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4c9dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n",
      "tensor([0.4433, 1.1419])\n",
      "tensor([0.3951, 1.0037])\n"
     ]
    }
   ],
   "source": [
    "print(query_2)\n",
    "print(key_2)\n",
    "print(value_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a892c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even though for finding context vector for query 2\n",
    "# we need to find key, value vectors for all input elements as they\n",
    "# involved in computing attention weights with respect to query 2\n",
    "\n",
    "\n",
    "keys=inputs@W_key\n",
    "values=inputs@W_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d01a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3669, 0.7646],\n",
      "        [0.4433, 1.1419],\n",
      "        [0.4361, 1.1156],\n",
      "        [0.2408, 0.6706],\n",
      "        [0.1827, 0.3292],\n",
      "        [0.3275, 0.9642]])\n",
      "torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "print(keys)\n",
    "print(keys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2f9718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1855, 0.8812],\n",
      "        [0.3951, 1.0037],\n",
      "        [0.3879, 0.9831],\n",
      "        [0.2393, 0.5493],\n",
      "        [0.1492, 0.3346],\n",
      "        [0.3221, 0.7863]])\n",
      "torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "print(values)\n",
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09508487",
   "metadata": {},
   "source": [
    "*computing attention scores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1484629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2705)\n"
     ]
    }
   ],
   "source": [
    "# to fidning attn socre = dot prodcut of query and keys\n",
    "\n",
    "# we've taken for query 2\n",
    "# attention score wrt query 1\n",
    "keys_1=keys[0]\n",
    "attn_score_21=query_2.dot(keys_1)\n",
    "print(attn_score_21)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "260f8e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "# attn score wrt query 2\n",
    "keys_2=keys[1]\n",
    "attn_score_22=query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a797083a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "# attention score for given inputs wrt query 2\n",
    "attn_scores_2 = query_2@keys.T\n",
    "print(attn_scores_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10d5acdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "print(keys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0813608",
   "metadata": {},
   "source": [
    "*computing attention weights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "231cfe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "d_k=keys.shape[-1] # embedding dimension of keys\n",
    "\n",
    "# attention score scaled: dividing them by sqrt of d_k\n",
    "attn_weights_2=torch.softmax(attn_scores_2/d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d6312a",
   "metadata": {},
   "source": [
    "*context vector*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "426a0cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2=attn_weights_2@values\n",
    "print(context_vec_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589cfb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
