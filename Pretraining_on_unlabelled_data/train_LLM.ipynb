{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fcbe956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from GPT_module import GPTModel\n",
    "from utility_module import text_to_token_ids, token_ids_to_text, generate_text_simple, calc_loss_batch, calc_loss_loader, create_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cfa9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # vocabsize from BPE tokenizer\n",
    "    \"context_length\": 256,  # context length\n",
    "    \"emb_dim\": 768,  # embedding dimension\n",
    "    \"n_heads\": 12,  # number of attention heads\n",
    "    \"n_layers\": 12,  # number of layers\n",
    "    \"drop_rate\": 0.1,  # dropout rate\n",
    "    \"qkv_bias\": False  # query-key-value bias\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a48fd8",
   "metadata": {},
   "source": [
    "*evaluate model loss function*\n",
    "\n",
    "*it calculates the loss over the training and validation set while ensuring the model is in evaluation mode with gradient tracking and dropout disabled when calculating loss over training and validation sets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5127762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad(): # gradient tracking, dropout disabled\n",
    "        train_loss=calc_loss_loader(train_loader,model, device,num_batches=eval_iter)\n",
    "        val_loss=calc_loss_loader(val_loader,model,device,num_batches=eval_iter)\n",
    "\n",
    "    model.train() # resetting in training mode\n",
    "    return train_loss, val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89161bf8",
   "metadata": {},
   "source": [
    "*generate and print samples*\n",
    "\n",
    "*it tracks models improvment during training. Generally take text snippet as input, convert to token IDs, feed into LLM and generate text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a0afbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size=model.pos_emb.weight.shape[0]\n",
    "    encoded=text_to_token_ids(start_context,tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids=generate_text_simple(idx=encoded,max_new_tokens=50,context_size=context_size,model=model)\n",
    "        decoded_text=token_ids_to_text(token_ids,tokenizer)\n",
    "        print(decoded_text)\n",
    "    model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a533d9",
   "metadata": {},
   "source": [
    "**The main function for pretraining LLMs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff195cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen=[],[],[]\n",
    "    tokens_seen, global_step=0,-1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss=calc_loss_batch(input_batch=input_batch,target_batch=target_batch,model=model,device=device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen+=input_batch.numel()\n",
    "            global_step+=1\n",
    "\n",
    "            if global_step%eval_freq==0:\n",
    "                train_loss, val_loss=evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                \n",
    "                print(f\"Epoch {epoch+1} (step{global_step:06d})| Train Loss {train_loss:.3f}| Val Loss {val_loss:.3f}\")\n",
    "\n",
    "        \n",
    "        generate_and_print_sample(model,tokenizer,device,start_context)\n",
    "    return train_losses,val_losses, track_tokens_seen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7b6a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "file_path = 'the-verdict.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text_data = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "889c3953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n",
      "5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(total_characters)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cd014bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio*len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b4b5628",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader(text=train_data, batch_size=2,\n",
    "                                 max_length=GPT_CONFIG_124M[\"context_length\"], stride=GPT_CONFIG_124M[\"context_length\"], shuffle=True, drop_last=True, num_workers=0)\n",
    "val_loader = create_dataloader(text=val_data, batch_size=2,\n",
    "                               max_length=GPT_CONFIG_124M[\"context_length\"], stride=GPT_CONFIG_124M[\"context_length\"], shuffle=False, drop_last=False, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59447dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model=GPTModel(GPT_CONFIG_124M)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device=device)\n",
    "optimizer=torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs=10\n",
    "train_losses, val_losses, tokens_seen=train_model_simple(model=model,train_loader=train_loader,val_loader=val_loader,optimizer=optimizer,device=device,num_epochs=num_epochs,eval_freq=5, eval_iter=1, start_context=\"Every effort moves you\",tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49845935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
