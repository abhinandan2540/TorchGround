{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb04218",
   "metadata": {},
   "source": [
    "**calculating the text generation loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74c1367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from GPT_module import GPTModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a524dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # vocabsize from BPE tokenizer\n",
    "    \"context_length\": 256,  # context length\n",
    "    \"emb_dim\": 768,  # embedding dimension\n",
    "    \"n_heads\": 12,  # number of attention heads\n",
    "    \"n_layers\": 12,  # number of layers\n",
    "    \"drop_rate\": 0.1,  # dropout rate\n",
    "    \"qkv_bias\": False  # query-key-value bias\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5485c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16833,  3626,  6100],\n",
      "        [   40,  1107,   588]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "inputs=[]\n",
    "txt1=\"every effort moves\"\n",
    "txt2=\"I really like\"\n",
    "\n",
    "inputs.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "inputs.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "inputs=torch.stack(inputs, dim=0)\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be57f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3626,  6100,   345],\n",
      "        [ 1107,   588, 11311]])\n"
     ]
    }
   ],
   "source": [
    "targets=[]\n",
    "trgt1=\" effort moves you\"\n",
    "trgt2=\" really like chocolate\"\n",
    "\n",
    "targets.append(torch.tensor(tokenizer.encode(trgt1)))\n",
    "targets.append(torch.tensor(tokenizer.encode(trgt2)))\n",
    "targets=torch.stack(targets, dim=0)\n",
    "\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0656a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model=GPTModel(GPT_CONFIG_124M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0845999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.6724e-05, 1.5027e-05, 3.2775e-05,  ..., 2.3964e-05,\n",
      "          3.0719e-05, 5.1232e-06],\n",
      "         [2.2332e-05, 8.5586e-06, 1.0495e-05,  ..., 1.3228e-05,\n",
      "          3.0204e-05, 1.2358e-05],\n",
      "         [4.5784e-05, 1.5433e-05, 1.7120e-05,  ..., 2.0696e-05,\n",
      "          1.0507e-05, 1.2693e-05]],\n",
      "\n",
      "        [[2.5316e-05, 1.5702e-05, 2.9621e-05,  ..., 1.2330e-05,\n",
      "          4.0768e-05, 7.4719e-06],\n",
      "         [1.8416e-05, 3.2594e-05, 1.5835e-05,  ..., 9.4178e-06,\n",
      "          4.1412e-05, 1.1170e-05],\n",
      "         [3.9493e-05, 2.9333e-05, 2.1341e-05,  ..., 1.4200e-05,\n",
      "          1.7878e-05, 1.4096e-05]]])\n",
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# probablity score of the model output\n",
    "with torch.no_grad():\n",
    "    logits=model(inputs)\n",
    "probas=torch.softmax(logits, dim=-1)\n",
    "print(probas)\n",
    "print(probas.shape) # 2 samples, 3 tokens each, total vocab size 50257\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ede988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  682],\n",
      "         [ 2463],\n",
      "         [35303]],\n",
      "\n",
      "        [[ 8615],\n",
      "         [23248],\n",
      "         [34798]]])\n"
     ]
    }
   ],
   "source": [
    "# token ids by argmax func of probablities\n",
    "token_ids=torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(token_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dca643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# utility function token id to text\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dim\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe749f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " effort moves you\n",
      "ause compan sideways\n"
     ]
    }
   ],
   "source": [
    "# target output\n",
    "print(token_ids_to_text(targets[0],tokenizer))\n",
    "# output batch\n",
    "print(token_ids_to_text(token_ids[0].flatten(), tokenizer)) # flatten() convert into 1D tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbb363",
   "metadata": {},
   "source": [
    "*For each of the two input texts, we can print the initial softmax probablity scores corresponding to the target tokens*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcf90235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6369e-05, 1.5997e-05, 1.6926e-05])\n",
      "tensor([3.5901e-05, 1.7121e-05, 1.7967e-05])\n"
     ]
    }
   ],
   "source": [
    "text_ids=0\n",
    "target_probas_1=probas[text_ids, [0,1,2], targets[text_ids]]\n",
    "print(target_probas_1)\n",
    "\n",
    "text_ids=1\n",
    "target_probas_2 = probas[text_ids, [0, 1, 2], targets[text_ids]]\n",
    "print(target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0144015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.5433, -11.0431, -10.9867, -10.2348, -10.9752, -10.9270])\n"
     ]
    }
   ],
   "source": [
    "# log probablity\n",
    "log_probas=torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "872bf1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7850)\n"
     ]
    }
   ],
   "source": [
    "# average log probablity\n",
    "avg_log_probas=torch.mean(log_probas)\n",
    "print(avg_log_probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fabc5753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7850)\n"
     ]
    }
   ],
   "source": [
    "# negative avg log probablity\n",
    "neg_avg_log_probas=avg_log_probas*-1\n",
    "print(neg_avg_log_probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58270cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)\n",
    "print(targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f52e718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 50257])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# flatten these tensors\n",
    "logits_flat=logits.flatten(0,1) # model output\n",
    "targets_flat=targets.flatten() # target output\n",
    "\n",
    "print(logits_flat.shape)\n",
    "print(targets_flat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8d8d987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7850)\n"
     ]
    }
   ],
   "source": [
    "# cross entropy function\n",
    "loss=torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ddabb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48291.0156)\n"
     ]
    }
   ],
   "source": [
    "# perplexity\n",
    "perplexity=torch.exp(loss)\n",
    "print(perplexity) # model confused among 48291 tokens on which to generate next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b4ec80",
   "metadata": {},
   "source": [
    "**calculating the training and validation set losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f0ff1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='the-verdict.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text_data=f.read()\n",
    "# print(text_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "059d319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n",
      "5145\n"
     ]
    }
   ],
   "source": [
    "total_characters=len(text_data)\n",
    "total_tokens=len(tokenizer.encode(text_data))\n",
    "\n",
    "print(total_characters)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f7492",
   "metadata": {},
   "source": [
    "*a dataset for batched inputs and targets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80a02f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.input_ids=[]\n",
    "        self.target_ids=[]\n",
    "\n",
    "        token_ids=tokenizer.encode(text)\n",
    "\n",
    "        for i in range(0, len(token_ids)-max_length, stride):\n",
    "            input_chunk=token_ids[i:i+max_length]\n",
    "            target_chunk=token_ids[i+1:i+1+max_length]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index], self.target_ids[index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84e3c1",
   "metadata": {},
   "source": [
    "*creating a dataloader to generate batches with input target pairs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b19020f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def create_dataloader(text, batch_size, max_length, stride, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset=GPTDataset(text=text,tokenizer=tokenizer,max_length=max_length,stride=stride)\n",
    "    dataloader=DataLoader(dataset=dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last,num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7683fd",
   "metadata": {},
   "source": [
    "*splitting train data into 90% training, 10% validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7be9a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio=0.90\n",
    "split_idx=int(train_ratio*len(text_data))\n",
    "train_data=text_data[:split_idx]\n",
    "val_data=text_data[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e72d743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader=create_dataloader(text=train_data,batch_size=2, max_length=GPT_CONFIG_124M[\"context_length\"],stride=GPT_CONFIG_124M[\"context_length\"],shuffle=True, drop_last=True,num_workers=0)\n",
    "val_loader=create_dataloader(text=val_data,batch_size=2, max_length=GPT_CONFIG_124M[\"context_length\"],stride=GPT_CONFIG_124M[\"context_length\"],shuffle=False, drop_last=False,num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee43574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e57ac21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(x.shape,y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5843822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce67d97d",
   "metadata": {},
   "source": [
    "*utility function to calculate loss of a given batch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c3d3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch,model, device):\n",
    "    input_batch, target_batch=input_batch.to(device), target_batch.to(device)\n",
    "    logits=model(input_batch)\n",
    "    loss=torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb007aa7",
   "metadata": {},
   "source": [
    "**Function to compute training and validation loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af6d588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss=0\n",
    "    if len(data_loader)==0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches=len(data_loader)\n",
    "    else:\n",
    "        num_batches=min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i<num_batches:\n",
    "            loss=calc_loss_batch(input_batch=input_batch, target_batch=target_batch,model=model, device=device)\n",
    "            total_loss+=loss.item()\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    return total_loss/num_batches\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d805993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.988623089260525\n",
      "10.993637084960938\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss=calc_loss_loader(train_loader,model,device)\n",
    "    val_loss=calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(train_loss)\n",
    "print(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae65dd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
